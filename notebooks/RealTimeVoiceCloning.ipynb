{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RealTimeVoiceCloning.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trunear/background-removal-js/blob/main/notebooks/RealTimeVoiceCloning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhDehA7sT-Gx"
      },
      "source": [
        "# Real-Time Voice Cloning\n",
        "\n",
        "This is a colab demo notebook using the open source project [CorentinJ/Real-Time-Voice-Cloning](https://github.com/CorentinJ/Real-Time-Voice-Cloning)\n",
        "to clone a voice.\n",
        "\n",
        "For other deep-learning Colab notebooks, visit [tugstugi/dl-colab-notebooks](https://github.com/tugstugi/dl-colab-notebooks).\n",
        "\n",
        "\n",
        "Original issue: https://github.com/tugstugi/dl-colab-notebooks/issues/18\n",
        "\n",
        "## Setup CorentinJ/Real-Time-Voice-Cloning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfkTM9TjUCRx",
        "outputId": "7d1ad8b6-af25-4fd3-af36-333f28e9a84c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title Setup CorentinJ/Real-Time-Voice-Cloning\n",
        "\n",
        "#@markdown * clone the project\n",
        "#@markdown * download pretrained models\n",
        "#@markdown * initialize the voice cloning models\n",
        "\n",
        "# Remove the line below as TensorFlow 1.x is no longer supported in Colab\n",
        "# %tensorflow_version 1.x\n",
        "import os\n",
        "from os.path import exists, join, basename, splitext\n",
        "\n",
        "git_repo_url = 'https://github.com/CorentinJ/Real-Time-Voice-Cloning.git'\n",
        "project_name = splitext(basename(git_repo_url))[0]\n",
        "if not exists(project_name):\n",
        "  # clone and install\n",
        "  !git clone -q --recursive {git_repo_url}\n",
        "  # install dependencies\n",
        "  !cd {project_name} && pip install -q -r requirements.txt\n",
        "  !pip install -q --upgrade gdown\n",
        "  !apt-get install -qq libportaudio2\n",
        "  !pip install -q https://github.com/tugstugi/dl-colab-notebooks/archive/colab_utils.zip\n",
        "\n",
        "  # download pretrained model\n",
        "  #!cd {project_name} && wget https://github.com/blue-fish/Real-Time-Voice-Cloning/releases/download/v1.0/pretrained.zip && unzip -o pretrained.zip\n",
        "  !cd {project_name} && mkdir -p saved_models/default/\n",
        "  !cd {project_name}/saved_models/default/ && gdown https://drive.google.com/uc?id=1q8mEGwCkFy23KZsinbuvdKAQLqNKbYf1\n",
        "  !cd {project_name}/saved_models/default/ && gdown https://drive.google.com/uc?id=1EqFMIbvxffxtjiVrtykroF6_mUh-5Z3s\n",
        "  !cd {project_name}/saved_models/default/ && gdown https://drive.google.com/uc?id=1cf2NO6FtI0jDuy8AV3Xgn6leO6dHjIgu\n",
        "\n",
        "import sys\n",
        "sys.path.append(project_name)\n",
        "\n",
        "from IPython.display import display, Audio, clear_output\n",
        "from IPython.utils import io\n",
        "import ipywidgets as widgets\n",
        "import numpy as np\n",
        "from dl_colab_notebooks.audio import record_audio, upload_audio\n",
        "\n",
        "from synthesizer.inference import Synthesizer\n",
        "from encoder import inference as encoder\n",
        "from vocoder import inference as vocoder\n",
        "from pathlib import Path\n",
        "\n",
        "!ls\n",
        "encoder.load_model(project_name / Path(\"saved_models/default/encoder.pt\"))\n",
        "synthesizer = Synthesizer(project_name / Path(\"saved_models/default/synthesizer.pt\"))\n",
        "vocoder.load_model(project_name / Path(\"saved_models/default/vocoder.pt\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.3/35.3 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBeMoBxLkDKN"
      },
      "source": [
        "#@title Record or Upload\n",
        "#@markdown * Either record audio from microphone or upload audio from file (.mp3 or .wav)\n",
        "\n",
        "SAMPLE_RATE = 22050\n",
        "record_or_upload = \"Upload (.mp3 or .wav)\" #@param [\"Record\", \"Upload (.mp3 or .wav)\"]\n",
        "record_seconds =   10#@param {type:\"number\", min:1, max:10, step:1}\n",
        "\n",
        "embedding = None\n",
        "def _compute_embedding(audio):\n",
        "  display(Audio(audio, rate=SAMPLE_RATE, autoplay=True))\n",
        "  global embedding\n",
        "  embedding = None\n",
        "  embedding = encoder.embed_utterance(encoder.preprocess_wav(audio, SAMPLE_RATE))\n",
        "def _record_audio(b):\n",
        "  clear_output()\n",
        "  audio = record_audio(record_seconds, sample_rate=SAMPLE_RATE)\n",
        "  _compute_embedding(audio)\n",
        "def _upload_audio(b):\n",
        "  clear_output()\n",
        "  audio = upload_audio(sample_rate=SAMPLE_RATE)\n",
        "  _compute_embedding(audio)\n",
        "\n",
        "if record_or_upload == \"Record\":\n",
        "  button = widgets.Button(description=\"Record Your Voice\")\n",
        "  button.on_click(_record_audio)\n",
        "  display(button)\n",
        "else:\n",
        "  #button = widgets.Button(description=\"Upload Voice File\")\n",
        "  #button.on_click(_upload_audio)\n",
        "  _upload_audio(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZjKkvGF1Y-i",
        "cellView": "form"
      },
      "source": [
        "#@title Synthesize a text { run: \"auto\" }\n",
        "text = \"One of the two people who tested positive for the novel coronavirus in the United Kingdom is a student at the University of York in northern England.\" #@param {type:\"string\"}\n",
        "\n",
        "def synthesize(embed, text):\n",
        "  print(\"Synthesizing new audio...\")\n",
        "  #with io.capture_output() as captured:\n",
        "  specs = synthesizer.synthesize_spectrograms([text], [embed])\n",
        "  generated_wav = vocoder.infer_waveform(specs[0])\n",
        "  generated_wav = np.pad(generated_wav, (0, synthesizer.sample_rate), mode=\"constant\")\n",
        "  clear_output()\n",
        "  display(Audio(generated_wav, rate=synthesizer.sample_rate, autoplay=True))\n",
        "\n",
        "if embedding is None:\n",
        "  print(\"first record a voice or upload a voice file!\")\n",
        "else:\n",
        "  synthesize(embedding, text)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}